{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e21c03",
   "metadata": {},
   "source": [
    "# CV Lab 8\n",
    "# Shresht Mishra\n",
    "# 211020450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f38601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a8f3d7",
   "metadata": {},
   "source": [
    "## 1.Object detection from a given video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ca5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79af64cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1732c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"D:/CV/Lab 8/title-artist.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e899f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"D:/CV/Lab 8/output_video_yolo.mp4\"\n",
    "codec = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output_writer = cv2.VideoWriter(output_path, codec, 30.0, (int(cap.get(3)), int(cap.get(4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8462a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the blob from the frame and perform YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    layer_names = yolo_net.getUnconnectedOutLayersNames()\n",
    "    detections = yolo_net.forward(layer_names)\n",
    "\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                # Get the coordinates and size of the bounding box\n",
    "                center_x, center_y, width, height = map(int, obj[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]))\n",
    "                x, y = center_x - width // 2, center_y - height // 2\n",
    "\n",
    "                # Draw bounding box and label on the frame\n",
    "                color = (0, 255, 0)  # Green\n",
    "                cv2.rectangle(frame, (x, y), (x + width, y + height), color, 2)\n",
    "                label = f\"{classes[class_id]}: {confidence:.2f}\"\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Write the frame with bounding boxes to the output video\n",
    "    output_writer.write(frame)\n",
    "    \n",
    "cap.release()\n",
    "output_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4768d71",
   "metadata": {},
   "source": [
    "## 2.Count the object from given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b4cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_count = [\"car\", \"motorbike\", \"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53dbdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {cls: 0 for cls in classes_to_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "178249d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_tracker = {}\n",
    "object_id_counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec1d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Get the blob from the frame and perform YOLO object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    yolo_net.setInput(blob)\n",
    "    layer_names = yolo_net.getUnconnectedOutLayersNames()\n",
    "    detections = yolo_net.forward(layer_names)\n",
    "\n",
    "    for detection in detections:\n",
    "        for obj in detection:\n",
    "            scores = obj[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "\n",
    "            if confidence > 0.5:\n",
    "                detected_class = classes[class_id]\n",
    "                if detected_class in classes_to_count:\n",
    "                    # Get the coordinates and size of the bounding box\n",
    "                    center_x, center_y, width, height = map(int, obj[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]]))\n",
    "                    x, y = center_x - width // 2, center_y - height // 2\n",
    "\n",
    "                    # Check if the object is already being tracked\n",
    "                    object_id = None\n",
    "                    for obj_id, (prev_x, prev_y, _, _) in object_tracker.items():\n",
    "                        if x >= prev_x and x <= prev_x + width and y >= prev_y and y <= prev_y + height:\n",
    "                            object_id = obj_id\n",
    "                            break\n",
    "\n",
    "                    if object_id is None:\n",
    "                        # New object detected, assign a unique ID\n",
    "                        object_id = object_id_counter\n",
    "                        object_id_counter += 1\n",
    "\n",
    "                    # Update the object tracker with the new coordinates\n",
    "                    object_tracker[object_id] = (x, y, width, height)\n",
    "\n",
    "                    # Increment the count for the detected class\n",
    "                    class_counts[detected_class] += 1\n",
    "\n",
    "    # Draw counts on the frame\n",
    "    for cls, count in class_counts.items():\n",
    "        text = f\"{cls}: {count}\"\n",
    "        cv2.putText(frame, text, (10, 30 * (1 + classes_to_count.index(cls))), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with counts\n",
    "    cv2.imshow(\"Object Counting\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df84c957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cars detected: 11539\n",
      "Total motorbikes detected: 2903\n",
      "Total persons detected: 7629\n"
     ]
    }
   ],
   "source": [
    "for cls, count in class_counts.items():\n",
    "    print(f\"Total {cls}s detected: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202f67d",
   "metadata": {},
   "source": [
    "## 3.Apply compression and decompression concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7cb969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video_path = \"D:/CV/Lab 8/compressed_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e33c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frames_per_second = int(cap.get(5))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, frames_per_second, (frame_width, frame_height))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform any desired processing on the frame (e.g., object detection, etc.)\n",
    "    # Compressing here can also be done, but typically compression is done during export\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video objects\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ff4485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_compressed_video_path = \"D:/CV/Lab 8/compressed_video.mp4\"\n",
    "output_decompressed_video_path = \"D:/CV/Lab 8/decompressed_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238599d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(input_compressed_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4abe6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frames_per_second = int(cap.get(5))\n",
    "\n",
    "# Define the codec and create a VideoWriter object for the decompressed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed\n",
    "out = cv2.VideoWriter(output_decompressed_video_path, fourcc, frames_per_second, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform any desired processing on the frame if needed\n",
    "    \n",
    "    # Write the frame to the decompressed video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video objects\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ec1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
